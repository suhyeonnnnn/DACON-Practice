{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhyeonnnnn/DACON-Practice/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAg3wfwA6qPB"
      },
      "outputs": [],
      "source": [
        "NGROK_TOKEN = '2VHdwYwKgPdECzEwLbeortiheWl_7YXY3i1KmrmG2QmWffKp4'\n",
        "PASSWORD = '9213'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaPOFoRP6z_V",
        "outputId": "30045881-3ba9-4fd9-cc38-96847562129a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 12 16:16:21 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# gpu 확인\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozdKNeVD64uF",
        "outputId": "f8866d6f-a721-48eb-dc2b-3efb11188afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colab-ssh\n",
            "  Downloading colab_ssh-0.3.27-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: colab-ssh\n",
            "Successfully installed colab-ssh-0.3.27\n"
          ]
        }
      ],
      "source": [
        "!pip install colab-ssh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMcr--9Z7LKT",
        "outputId": "cb7d2537-03f6-4466-9783-c25de16def76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Due to some issues with ngrok on Google Colab, reported in the issue https://github.com/WassimBenzarti/colab-ssh/issues/45, \n",
            "we highly recommend that update your code by following this documentation https://github.com/WassimBenzarti/colab-ssh#getting-started\n",
            "Successfully running 8.tcp.ngrok.io:18400\n",
            "[Optional] You can also connect with VSCode SSH Remote extension using this configuration:\n",
            "\n",
            "  Host google_colab_ssh\n",
            "    HostName 8.tcp.ngrok.io\n",
            "    User root\n",
            "    Port 18400\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "from colab_ssh import launch_ssh\n",
        "launch_ssh(NGROK_TOKEN, PASSWORD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aue7oWneBew",
        "outputId": "0d453c57-cdae-4566-9c89-401c4da186fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/samsumgAIchallenge"
      ],
      "metadata": {
        "id": "y8BGyVjjRVhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miLIKXQrR0jZ",
        "outputId": "96049560-85b9-4fab-9862-5bd9ec21fba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset.py  main.ipynb\tmodels.py  __pycache__\tutils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n"
      ],
      "metadata": {
        "id": "malm1L6_TUym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE9EMIJSQfjW",
        "outputId": "907c2c75-902e-406e-b877-5a67690661a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dataset"
      ],
      "metadata": {
        "id": "PEcMZldCRQ7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIzNcGHO59rk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "444679f2-3f5a-492f-fca7-e8c832c3e276"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a04c06e24ce2>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#dataset = CustomDataset(csv_file='./train_source.csv', transform=transform)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# data loader\n",
        "transform = A.Compose(\n",
        "    [\n",
        "        A.Resize(224, 224),\n",
        "        A.Normalize(),\n",
        "        ToTensorV2()\n",
        "    ]\n",
        ")\n",
        "\n",
        "dataset = CustomDataset(csv_file='./train_source.csv', transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model 초기화\n",
        "model = UNet().to(device)\n",
        "\n",
        "# loss function & optimizer 정의\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# training loop\n",
        "for epoch in range(20): # 20 epoch 동안 학습\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  for images, masks in tqdm(dataloader):\n",
        "    images = images.float().to(device)\n",
        "    mask = masks.long().to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, masks.squeeze(1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "  print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}')\n"
      ],
      "metadata": {
        "id": "xFdXz7Cdgsce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# infernce"
      ],
      "metadata": {
        "id": "tSSIpDd-Uvx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  result = []\n",
        "\n",
        "  for images in tqdm(test_dataloader):\n",
        "    images = images.float().to(device)\n",
        "    outputs = model(images)\n",
        "    outputs = torch.softmax(outputs, dim = 1).cpu()\n",
        "    outputs = torch.argmax(outputs, dim = 1).numpy()\n",
        "\n",
        "    # batch에 존재하는 각 이미지에 대해서 반복\n",
        "    for pred in outputs():\n",
        "      pred = pred.astype(np.unit8)\n",
        "      pred = Image.fromarray(pred) # 이미지로 변환\n",
        "      pred = pred.resize((960, 540), Image.NEAREST) # 960 X 540 사이즈로 변환\n",
        "      pred = np.array(pred) # 다시 수치로 변환\n",
        "      # class 0 ~ 11에 해당하는 경우에 마스크 생성 (배경(12)는 제외)\n",
        "      for class_id in range(12):\n",
        "        class_mask = (pred==class_id).astype(np.unit8)\n",
        "        if np.sum(class_mask) > 0: # 마스크가 존재하는 경우 encode\n",
        "          mask_rle = rle_encode(class_mask)\n",
        "          result.append(mask_rle)\n",
        "        else:\n",
        "          result.append(-1)\n"
      ],
      "metadata": {
        "id": "3lOC0piQUuIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# submission\n",
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "submit['mask_rle'] = result\n",
        "submit.head(3)"
      ],
      "metadata": {
        "id": "CC8wSq0Ry4y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv('./basline_submit.csv', index = False)"
      ],
      "metadata": {
        "id": "5BW9qyOPzBFZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}